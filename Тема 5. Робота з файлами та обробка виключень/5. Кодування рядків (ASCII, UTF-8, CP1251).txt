Кодування рядків (ASCII, UTF-8, CP1251)

Перші комп'ютери для роботи з текстом використовували так зване ASCII кодування. У цьому кодуванні 
для запису одного символу використовується один байт.

Зручність цього кодування в тому, що будь-які дані на комп'ютері можна спробувати представити 
у вигляді тексту в цьому кодуванні. ASCII містить 256 символів. Це не дуже багато і деякий 
час цього було достатньо. Але з часом алфавіту з 256 символів стало мало, виникла необхідність 
додати все більше символів (кирилиця, діакритичні знаки, коди валют, ієрогліфи тощо). 
Щоб задовольнити потребу у додаванні нових символів, придумали використати кодування, 
де більше одного байту на символ. Python за замовчуванням використовує UTF-8, в якій 
один символ може займати від 1 до 4 байт, і всього в алфавіті може бути до 1 112 064 
знаків. Це не єдине кодування, на різних платформах можуть бути присутні власні, 
наприклад CP-1251 (кирилиця на ОС сімейства Windows), UTF-16, UTF-32 та інші.

Щоб дізнатися, якому елементу в UTF-8 відповідає символ, є функція ord (від order).

Наприклад, символ 'a' кодується числом 97:

ord('a')  # 97

Зворотна операція, коли потрібно дізнатися, який символ закодований числом, наприклад 
100, є функція chr (скорочено від character):

chr(128)  # 'd'

Python може працювати з дуже великою кількістю різних кодувань.

✂️ Цей код можна запустити! 

s = "Привіт!"

utf8 = s.encode()
print(f"UTF-8: {utf8}")

utf16 = s.encode("utf-16")
print(f"UTF-16: {utf16}")

cp1251 = s.encode("cp1251")
print(f"CP-1251: {cp1251}")

s_from_utf16 = utf16.decode("utf-16")
print(s_from_utf16 == s)

Виведення:

UTF-8: b'\xd0\x9f\xd1\x80\xd0\xb8\xd0\xb2\xd1\x96\xd1\x82!'
UTF-16: b'\xff\xfe\x1f\x04@\x048\x042\x04V\x04B\x04!\x00'
CP-1251: b'\xcf\xf0\xe8\xe2\xb3\xf2!'
True

Спроба перетворити байт-рядок в неправильному кодуванні, призводить або до помилки, 
або до досить непередбачуваного результату:

✂️ Цей код можна запустити! 

print(b'Hello world!'.decode('utf-16'))

Виведення якщо кодування UTF-8 ми намагаємось декодувати в UTF-16:

效汬⁯潷汲Ⅴ

А тепер до важливого, навіщо нам знати про інші стандарт, якщо зараз все в UTF-8. При роботі 
з файлами в операційній системі Windows часто виникає проблема, пов'язана зі стандартним 
кодуванням. Windows за замовчуванням використовує кодування CP-1251 (також відоме як Windows-1251), 
яке є стандартним для багатьох країн, де використовується кирилиця. Це кодування істотно 
відрізняється від UTF-8, яке є універсальним і підтримує широкий спектр символів з різних 
мов. А нагадаємо, що стандарт зараз всюди це саме UTF-8.

Коли файл зберігається в кодуванні, відмінному від UTF-8, і потім відкривається у програмі, 
яка очікує UTF-8 (або навпаки), це може призвести до неправильного відображення тексту. 
Символи, які не відповідають стандарту кодування, можуть відображатися як нерозпізнані 
знаки або викликати помилки при читанні файлу.

Щоб уникнути проблем з кодуванням, особливо при роботі з міжнародними текстами або в середовищах 
з різними налаштуваннями кодування, рекомендується завжди явно вказувати кодування UTF-8 під час 
відкриття файлів у Python. Це можна зробити за допомогою параметра encoding у функції open().

✂️ Цей код можна запустити! 

# Відкриття текстового файлу з явним вказівкам UTF-8 кодування
with open('example.txt', 'r', encoding='utf-8') as file:
    content = file.read()
    print(content)

У цьому прикладі, навіть якщо операційна система використовує інше кодування за замовчуванням, 
файл буде коректно відкритий із використанням UTF-8, що гарантує правильне відображення тексту.

У світі, де дані часто обмінюються між різними системами та платформами, уніфікація кодування 
до UTF-8 є ключовим фактором для забезпечення сумісності та коректності обробки текстових даних. 
Вказання кодування при відкритті файлів функцією open() допомагає уникнути багатьох проблем, 
пов'язаних з локалізацією та міжнародною підтримкою.